{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oloXVHqZlXxb"
      },
      "source": [
        "Review:\n",
        "\n",
        "Table is called a dataframe short for df and a columm is called a series\n",
        "\n",
        "useful df functions:\n",
        "\n",
        ".head, .shape, .info, .describe\n",
        "\n",
        "to access specific column will use df_name[\"column name\"] and then filter rows as  dog[dogs[\"date of birth\"] > 50]\n",
        "\n",
        "for categricla data use the isin method to filter rows.\n",
        "\n",
        "sorting example:\n",
        "\n",
        "# Sort homelessness by descending family members\n",
        "homelessness_fam = homelessness.sort_values(\"family_members\", ascending=False)\n",
        "\n",
        "# Sort homelessness by region, then descending family members\n",
        "homelessness_reg_fam = homelessness.sort_values([\"region\", \"family_members\"], ascending=[True, False])\n",
        "\n",
        "# Print the top few rows\n",
        "print(homelessness_reg_fam.head())\n",
        "\n",
        "# Filter categorical data\n",
        "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
        "\n",
        "mojave_homelessness = homelessness[homelessness[\"state\"].isin(canu)]\n",
        "\n",
        "print(mojave_homelessness)\n",
        "\n",
        "# Using filter and creating new columsn to find specific data to find \"Which state has the highest number of homeless individuals per 10,000 people in the state?\" Combine your new pandas skills to find out\n",
        "\n",
        "-> Create indiv_per_10k col as homeless individuals per 10k state pop\n",
        "\n",
        "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"]\n",
        "\n",
        "-> Subset rows for indiv_per_10k greater than 20\n",
        "\n",
        "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
        "\n",
        "-> Sort high_homelessness by descending indiv_per_10k\n",
        "\n",
        "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
        "\n",
        "-> From high_homelessness_srt, select the state and indiv_per_10k cols\n",
        "\n",
        "result = high_homelessness_srt[[\"state\",\"indiv_per_10k\"]]\n",
        "\n",
        "-> See the result\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdZfHOV3laRO"
      },
      "source": [
        "Project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xPUwDDZccX6I"
      },
      "outputs": [],
      "source": [
        "import numpy as np #  particularly useful when dealing with arrays and matrices\n",
        "import pandas as pd #Pandas is a powerful data manipulation and analysis library built on top of NumPy.\n",
        "# It's particularly well-suited for handling structured data and is widely used in data science and machine learning workflows.\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us3k4oqshLTE"
      },
      "source": [
        "- Use scikit-learn for traditional machine learning tasks, rapid prototyping, small to medium-sized datasets, and standard preprocessing tasks.\n",
        "- Use TensorFlow for deep learning, handling large-scale datasets, production deployment, advanced machine learning techniques, and tasks requiring high flexibility and performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W5b3ZloPgLWb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h2TeYRehKj_"
      },
      "source": [
        "Visual Example\n",
        "Classification Example:\n",
        "\n",
        "Task: Classify whether a customer will buy a product (Yes/No).\n",
        "Input Features: Age, Income, Browsing History.\n",
        "Output: \"Yes\" or \"No\".\n",
        "Regression Example:\n",
        "\n",
        "Task: Predict the price of a house.\n",
        "Input Features: Size of the house, Number of bedrooms, Location.\n",
        "Output: A continuous value representing the price of the house (e.g., $250,000)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IvqwoUnazA2h"
      },
      "outputs": [],
      "source": [
        "# reading in our data using .read_csv another ways are\n",
        "# - pd.read_excel, pd.read_sql, pd.read_json, pd.read_html,\n",
        "\n",
        "df = pd.read_csv(\"/Users/evercampos/DataS/Sleep_health_and_lifestyle_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUjD3E7SjlsJ"
      },
      "source": [
        "# As we read this csv file what can we learn from this data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmuXDeeSRekx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
